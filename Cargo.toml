[package]
name = "islands"
description = "LEANN-based codebase indexing with MCP server and AI-powered search"
version = "1.5.0"
edition = "2024"
rust-version = "1.85"
license = "MIT"
authors = ["Jonathan Reyes <me@jonathanreyes.com>"]
repository = "https://github.com/panbanda/islands"
documentation = "https://github.com/panbanda/islands#readme"
keywords = ["mcp", "semantic-search", "codebase-indexing", "leann", "rag", "vector-database"]
categories = ["command-line-utilities", "development-tools", "science"]

[package.metadata.models]
# Sentence transformer model for semantic embeddings (HuggingFace ONNX format)
# Model: all-MiniLM-L6-v2 - 384-dimensional embeddings, optimized for semantic similarity
sentence_transformer_model = "sentence-transformers/all-MiniLM-L6-v2"
sentence_transformer_version = "v1.0.3"
sentence_transformer_dimension = 384
sentence_transformer_max_seq_length = 256

# Model files (relative to HuggingFace repo)
sentence_transformer_onnx_path = "onnx/model.onnx"
sentence_transformer_tokenizer_path = "tokenizer.json"

# Cache invalidation version (bump when model format changes)
model_cache_version = "1"

[[bin]]
name = "islands"
path = "src/main.rs"

[lib]
name = "islands"
path = "src/lib.rs"

[features]
default = ["mcp", "agent", "watch", "embeddings"]
mcp = []
agent = []
watch = ["notify"]
embeddings = ["embed_anything"]
embeddings-candle = ["candle-core", "candle-nn", "candle-transformers", "hf-hub", "tokenizers"]
metal = ["embeddings", "embed_anything/metal"]
cuda = ["embeddings", "embed_anything/cuda"]
candle-metal = ["embeddings-candle", "candle-core/metal", "candle-nn/metal"]
candle-cuda = ["embeddings-candle", "candle-core/cuda", "candle-core/cudnn", "candle-nn/cuda"]
openai = []
anthropic = []

[dependencies]
# Async runtime
tokio = { version = "1.49", features = ["full"] }
futures = "0.3.31"
async-trait = "0.1.89"

# HTTP client
reqwest = { version = "0.13.1", features = ["json", "query", "rustls", "stream"], default-features = false }

# Serialization
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.149"
serde_yaml = "0.9.34"
bincode = "1.3.3"

# CLI
clap = { version = "4.5.55", features = ["derive", "env"] }

# Logging and tracing
tracing = "0.1.44"
tracing-subscriber = { version = "0.3.22", features = ["env-filter", "json"] }

# Error handling
thiserror = "2.0.18"
anyhow = "1.0.100"

# Cryptography for webhook verification
hmac = "0.12.1"
sha2 = "0.10.9"
hex = "0.4.3"

# OpenSSL (vendored for cross-compilation)
openssl = { version = "0.10.75", features = ["vendored"] }

# Git operations
gix = { version = "0.78.0", default-features = false, features = ["blocking-network-client"] }
git2 = "0.20.3"

# Configuration
config = "0.15.19"
dotenvy = "0.15.7"

# Date/time
chrono = { version = "0.4.43", features = ["serde"] }

# Path handling
directories = "6.0"
camino = { version = "1.2.2", features = ["serde1"] }

# UUID generation
uuid = { version = "1.20.0", features = ["v4", "serde"] }

# Base64 encoding
base64 = "0.22.1"

# URL parsing
url = "2.5.8"
urlencoding = "2.1.3"

# File watching (optional)
notify = { version = "8.2.0", optional = true }

# Async file operations
tokio-util = { version = "0.7.18", features = ["io"] }

# Vector operations
ndarray = "0.17.2"
ordered-float = "5.1.0"
rand = "0.9.2"
rand_chacha = "0.9.0"
parking_lot = "0.12.5"

# Embedding models (optional)
embed_anything = { version = "0.6.7", optional = true }

# Native Candle sentence embeddings (optional)
tokenizers = { version = "0.22.2", optional = true, default-features = false, features = ["onig"] }
candle-core = { version = "0.9.2", optional = true }
candle-nn = { version = "0.9.2", optional = true }
candle-transformers = { version = "0.9.2", optional = true }
hf-hub = { version = "0.4.3", optional = true, features = ["tokio"] }

# Directory walking
walkdir = "2.5"
ignore = "0.4.25"

# Pretty terminal output
console = "0.16.2"
indicatif = "0.18.3"
tabled = "0.20"

# Streaming for agent
async-stream = "0.3.6"
gix-url = "0.35.0"

[dev-dependencies]
mockall = "0.14"
tempfile = "3.24"
wiremock = "0.6.5"
proptest = "1.9"
proptest-derive = "0.7"
criterion = "0.8.1"
pretty_assertions = "1.4.1"
rstest = "0.26.1"
test-case = "3.3.1"
assert_matches = "1.5"
insta = "1.46.1"
tracing-test = "0.2.5"
tokio-test = "0.4.5"
assert_cmd = "2.1.2"
predicates = "3.1.3"

[lints.rust]
unsafe_code = "warn"
missing_docs = "allow"

[lints.clippy]
all = { level = "warn", priority = -1 }

[profile.release]
lto = "thin"
codegen-units = 1
panic = "abort"
strip = true

[profile.bench]
lto = "thin"
codegen-units = 1

[[bench]]
name = "hnsw_benchmarks"
harness = false

[[bench]]
name = "vector_ops"
harness = false

[[bench]]
name = "pq_compression"
harness = false
